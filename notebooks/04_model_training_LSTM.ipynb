{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# change current working directory to the root of the project\n",
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "- Purpose of this notebook is to train an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "from IPython.display import display\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Flatten, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from src.pipeline_transformers import ColumnDropperTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199293</th>\n",
       "      <td>25</td>\n",
       "      <td>8688572339000</td>\n",
       "      <td>10.53</td>\n",
       "      <td>14.90</td>\n",
       "      <td>14.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199294</th>\n",
       "      <td>25</td>\n",
       "      <td>8688622327000</td>\n",
       "      <td>3.17</td>\n",
       "      <td>15.70</td>\n",
       "      <td>15.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199295</th>\n",
       "      <td>25</td>\n",
       "      <td>8688672346000</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>15.79</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199296</th>\n",
       "      <td>25</td>\n",
       "      <td>8688722333000</td>\n",
       "      <td>6.13</td>\n",
       "      <td>10.23</td>\n",
       "      <td>10.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199297</th>\n",
       "      <td>25</td>\n",
       "      <td>8688772321000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.23</td>\n",
       "      <td>9.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id      timestamp      x      y      z\n",
       "199293       25  8688572339000  10.53  14.90  14.90\n",
       "199294       25  8688622327000   3.17  15.70  15.70\n",
       "199295       25  8688672346000  -1.04  15.79  15.79\n",
       "199296       25  8688722333000   6.13  10.23  10.23\n",
       "199297       25  8688772321000   0.08   9.23   9.23"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199293</th>\n",
       "      <td>Jogging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199294</th>\n",
       "      <td>Jogging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199295</th>\n",
       "      <td>Jogging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199296</th>\n",
       "      <td>Jogging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199297</th>\n",
       "      <td>Jogging</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       activity\n",
       "199293  Jogging\n",
       "199294  Jogging\n",
       "199295  Jogging\n",
       "199296  Jogging\n",
       "199297  Jogging"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrows = None\n",
    "X_train = pd.read_csv(\"data/transformed/X_train.csv\", nrows=nrows)\n",
    "X_val = pd.read_csv(\"data/transformed/X_val.csv\", nrows=nrows)\n",
    "X_test = pd.read_csv(\"data/transformed/X_test.csv\", nrows=nrows)\n",
    "\n",
    "y_train = pd.read_csv(\"data/transformed/y_train.csv\", nrows=nrows)\n",
    "y_val = pd.read_csv(\"data/transformed/y_val.csv\", nrows=nrows)\n",
    "y_test = pd.read_csv(\"data/transformed/y_test.csv\", nrows=nrows)\n",
    "\n",
    "display(X_val.tail())\n",
    "display(y_val.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 240 # length of each sequence\n",
    "steps = 40 # step size between sequences\n",
    "n_features = 3 \n",
    "n_classes = len(y_train[\"activity\"].unique().tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ani/Projects/4_sequence_classification_using_LSTM_CNN/.4_venv/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ani/Projects/4_sequence_classification_using_LSTM_CNN/.4_venv/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/ani/Projects/4_sequence_classification_using_LSTM_CNN/.4_venv/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/encoder.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize the data and convert back to dataframe\n",
    "columns = X_train.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=columns)\n",
    "X_val = pd.DataFrame(scaler.transform(X_val), columns=columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=columns)\n",
    "\n",
    "# label encode the target variable\n",
    "encoder = LabelEncoder()\n",
    "y_train = pd.DataFrame(encoder.fit_transform(y_train), columns=[\"activity\"])\n",
    "y_val = pd.DataFrame(encoder.transform(y_val), columns=[\"activity\"])\n",
    "y_test = pd.DataFrame(encoder.transform(y_test), columns=[\"activity\"])\n",
    "\n",
    "# save the scaler and encoder using joblib\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "joblib.dump(encoder, \"models/encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Downstairs', 'Jogging', 'Sitting', 'Standing', 'Upstairs',\n",
       "       'Walking'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X: pd.DataFrame, y: pd.DataFrame, n_timesteps: int = 80, steps: int = 40):\n",
    "    \"\"\"\n",
    "    Preprocess data for LSTM model.\n",
    "    \"\"\"\n",
    "\n",
    "    # merge X and y on index\n",
    "    data = X.merge(y, left_index=True, right_index=True)\n",
    "    \n",
    "    # select chunks of 240 timestamps with a step of 40 for each user and activity\n",
    "    chunks = []\n",
    "    activity = []\n",
    "    for index, df in data.groupby(['user_id', 'activity']):\n",
    "        # select chunks of 240 timestamps with a step of 40\n",
    "        for i in range(0, len(df), steps):\n",
    "            chunk = df[i:i+n_timesteps]\n",
    "            if len(chunk) == n_timesteps:\n",
    "                chunks.append(chunk[['x', 'y', 'z']].values.reshape(1, n_timesteps, 3))\n",
    "                activity.append(df['activity'].values[0])\n",
    "\n",
    "    X = np.concatenate(chunks, axis=0)\n",
    "    y = np.array(activity)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocess_data(X_train, y_train, timesteps, steps)\n",
    "X_val, y_val = preprocess_data(X_val, y_val, timesteps, steps)\n",
    "X_test, y_test = preprocess_data(X_test, y_test, timesteps, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=(15203, 240, 3)\n",
      "y_train.shape=(15203,)\n",
      "X_val.shape=(4834, 240, 3)\n",
      "y_val.shape=(4834,)\n",
      "X_test.shape=(6433, 240, 3)\n",
      "y_test.shape=(6433,)\n"
     ]
    }
   ],
   "source": [
    "print(f'{X_train.shape=}')\n",
    "print(f'{y_train.shape=}')\n",
    "print(f'{X_val.shape=}')\n",
    "print(f'{y_val.shape=}')\n",
    "print(f'{X_test.shape=}')\n",
    "print(f'{y_test.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    '''Takes in hyperparameters as input, and trains a model that computes accuracy on the validation set.'''\n",
    "    clear_session()\n",
    "\n",
    "    # define early stopping\n",
    "    early_stop = EarlyStopping(monitor='val_loss',patience=5)\n",
    "\n",
    "    # define model architecture\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "        LSTM(\n",
    "            units=trial.suggest_int(\"units\", 128, 512, log=True),\n",
    "            input_shape=(timesteps, n_features))))\n",
    "\n",
    "    model.add(Dropout(rate=trial.suggest_uniform(\"dropout\", 0.0, 0.5)))\n",
    "\n",
    "    model.add(Dense(units=trial.suggest_int(\"units\", 128, 512, log=True), activation='relu'))\n",
    "\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer='adam',\n",
    "        metrics=[\"sparse_categorical_accuracy\"])\n",
    "        \n",
    "    # fit model\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=20,\n",
    "        batch_size=trial.suggest_int(\"batch_size\", 32, 128, log=True),\n",
    "        validation_data=(X_val, y_val),\n",
    "        shuffle=True,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # compute validation error\n",
    "    score = model.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-04 09:23:44,855]\u001b[0m A new study created in memory with name: lstm\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 09:29:25,789]\u001b[0m Trial 0 finished with value: 0.6026065349578857 and parameters: {'units': 229, 'dropout': 0.3616264072373436, 'batch_size': 110}. Best is trial 0 with value: 0.6026065349578857.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 09:43:11,703]\u001b[0m Trial 1 finished with value: 0.7966487407684326 and parameters: {'units': 361, 'dropout': 0.012458431667391856, 'batch_size': 100}. Best is trial 1 with value: 0.7966487407684326.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 09:51:29,354]\u001b[0m Trial 2 finished with value: 0.566818356513977 and parameters: {'units': 327, 'dropout': 0.32309595017588744, 'batch_size': 68}. Best is trial 1 with value: 0.7966487407684326.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 10:00:01,836]\u001b[0m Trial 3 finished with value: 0.4077368676662445 and parameters: {'units': 332, 'dropout': 0.22441525582058403, 'batch_size': 67}. Best is trial 1 with value: 0.7966487407684326.\u001b[0m\n",
      "\u001b[32m[I 2023-04-04 10:11:09,542]\u001b[0m Trial 4 finished with value: 0.5955730080604553 and parameters: {'units': 235, 'dropout': 0.10578951364347206, 'batch_size': 75}. Best is trial 1 with value: 0.7966487407684326.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# optuna study\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"lstm\")\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params={'units': 361, 'dropout': 0.012458431667391856, 'batch_size': 100}\n"
     ]
    }
   ],
   "source": [
    "# print best parameters\n",
    "best_params = study.best_trial.params\n",
    "print(f'{best_params=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = best_params['units']\n",
    "dropout = best_params['dropout']\n",
    "batch_size = best_params['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n",
    "# define early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "# define model architecture\n",
    "best_model = Sequential()\n",
    "\n",
    "best_model.add(\n",
    "    Bidirectional(\n",
    "        LSTM(\n",
    "            units=units,\n",
    "            input_shape=(timesteps, n_features))))\n",
    "\n",
    "best_model.add(Dropout(rate=dropout))\n",
    "\n",
    "best_model.add(Dense(units=units, activation='relu'))\n",
    "\n",
    "best_model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "best_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer='adam',\n",
    "    metrics=[\"sparse_categorical_accuracy\"])\n",
    "    \n",
    "# fit model\n",
    "best_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val, y_val),\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(best_model.history.history)\n",
    "losses[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame(best_model.history.history)\n",
    "accuracy[['acc', 'val_acc']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model accuracy on the test set.\n",
    "score = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Predictions & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model using joblib\n",
    "joblib.dump(best_model, \"models/lstm_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred, columns=[\"predicted_activity\"])\n",
    "y_pred.to_csv(\"predictions/predictions_lstm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://link.springer.com/article/10.1007/s11370-021-00358-7 (CNN + LSTM)\n",
    "# https://ieeexplore.ieee.org/document/7881728 (CNN)\n",
    "# https://medium.com/@tanmaychauhan111/human-activity-recognition-using-lstm-cnn-8ccb1a42cb81\n",
    "# user mcnemars test to compare models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".3_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
