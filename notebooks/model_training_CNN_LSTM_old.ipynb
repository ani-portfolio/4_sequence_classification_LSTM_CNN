{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# change current working directory to the root of the project\n",
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "- Purpose of this notebook is to train an CNN + LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from IPython.display import display\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Flatten, Bidirectional, Conv1D, MaxPooling1D, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using joblib\n",
    "X_train = joblib.load(\"data/transformed/X_train.pkl\")\n",
    "X_val = joblib.load(\"data/transformed/X_val.pkl\")\n",
    "X_test = joblib.load(\"data/transformed/X_test.pkl\")\n",
    "\n",
    "y_train = joblib.load(\"data/transformed/y_train.pkl\")\n",
    "y_val = joblib.load(\"data/transformed/y_val.pkl\")\n",
    "y_test = joblib.load(\"data/transformed/y_test.pkl\")\n",
    "\n",
    "print(f'{X_train.shape=}')\n",
    "print(f'{y_train.shape=}')\n",
    "print(f'{X_test.shape=}')\n",
    "print(f'{y_test.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]\n",
    "n_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    '''Takes in hyperparameters as input, and trains a model that computes accuracy on the validation set.'''\n",
    "    clear_session()\n",
    "\n",
    "    # define early stopping\n",
    "    early_stop = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "    # define model architecture\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters=trial.suggest_categorical(\"filters\", [128, 128*2, 128*3, 128*4, 128*5]), kernel_size=3, activation='relu', input_shape=(timesteps,n_features)))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(Dropout(trial.suggest_uniform(\"dropout\", 0.0, 0.5)))\n",
    "\n",
    "    model.add(Conv1D(filters=trial.suggest_categorical(\"filters\", [128, 128*2, 128*3, 128*4, 128*5]), kernel_size=3, activation='relu'))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(Dropout(trial.suggest_uniform(\"dropout\", 0.0, 0.5)))\n",
    "\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model.add(\n",
    "            LSTM(\n",
    "                units=trial.suggest_categorical(\"units\", [128, 128*2, 128*3, 128*4, 128*5]),\n",
    "                return_sequences=True))\n",
    "    \n",
    "    model.add(\n",
    "        LSTM(\n",
    "            units=trial.suggest_categorical(\"units\", [128, 128*2, 128*3, 128*4, 128*5])))\n",
    "\n",
    "    model.add(Dropout(trial.suggest_uniform(\"dropout\", 0.0, 0.5)))\n",
    "    \n",
    "    model.add(Dense(units=trial.suggest_categorical(\"units\", [128, 128*2, 128*3, 128*4, 128*5]), activation='relu'))\n",
    "\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer='adam',\n",
    "        metrics=[\"sparse_categorical_accuracy\"])\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        shuffle=False,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # compute validation error\n",
    "    score = model.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# optuna study\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"cnn_lstm\")\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters\n",
    "best_params = study.best_trial.params\n",
    "print(f'{best_params=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = best_params['units']\n",
    "dropout = best_params['dropout']\n",
    "filters = best_params['filters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n",
    "# define early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "# define model architecture\n",
    "best_model = Sequential()\n",
    "\n",
    "best_model.add(Conv1D(filters=filters, kernel_size=3, activation='relu', input_shape=(timesteps,n_features)))\n",
    "\n",
    "best_model.add(Dropout(dropout))\n",
    "\n",
    "best_model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "best_model.add(\n",
    "        Bidirectional(LSTM(\n",
    "            units=units,\n",
    "            input_shape=(timesteps, n_features))))\n",
    "\n",
    "best_model.add(\n",
    "        Bidirectional(LSTM(\n",
    "            units=units,\n",
    "            input_shape=(timesteps, n_features))))\n",
    "\n",
    "best_model.add(Dropout(dropout))\n",
    "\n",
    "best_model.add(Dense(units=units))\n",
    "\n",
    "best_model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "best_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer='adam',\n",
    "    metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "# fit model\n",
    "best_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    shuffle=False,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(best_model.history.history)\n",
    "losses[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame(best_model.history.history)\n",
    "accuracy[['sparse_categorical_accuracy', 'val_sparse_categorical_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model accuracy on the test set.\n",
    "score = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Predictions & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model using joblib\n",
    "joblib.dump(best_model, \"models/cnn_lstm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred, columns=[\"predicted_activity\"])\n",
    "y_pred.to_csv(\"predictions/predictions_cnn_lstm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://link.springer.com/article/10.1007/s11370-021-00358-7 (CNN + LSTM)\n",
    "# https://ieeexplore.ieee.org/document/7881728 (CNN)\n",
    "# https://medium.com/@tanmaychauhan111/human-activity-recognition-using-lstm-cnn-8ccb1a42cb81\n",
    "# user mcnemars test to compare models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".3_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
